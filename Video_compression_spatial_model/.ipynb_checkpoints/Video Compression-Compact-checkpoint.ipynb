{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\"><font face = \"With The Name Of GOD , The Most Merciful \" size = \"70\"  >With The Name Of GOD , The Most Merciful </font></h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\"><font face = \"Video Compression \" size = \"70\"  >Video Compression</font></h1>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook main reference :\n",
    "This notebook and Motion_Estimation_and_Compensation notebook are our own implementaton for chapter 3 of *\"H.264 and MPEG-4 Video Compression Video Coding for Next-generation Multimedia\" *By Iain E. G. Richardson The Robert Gordon University, Aberdeen, UK*  \n",
    "We have used Discrete Cosine Transform  for spatial model , and huffman for entropy encoding ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video Compression:\n",
    "\n",
    "Compression is the process of compacting data into a smaller number of bits. Video compression (video coding) is the process of compacting or condensing a digital video sequence\n",
    "into a smaller number of bits. ‘Raw’ or uncompressed digital video typically requires a\n",
    "large bitrate (approximately 216 Mbits for 1 second of uncompressed TV-quality video, see\n",
    " and compression is necessary for practical storage and transmission of digital\n",
    "video. \n",
    "\n",
    "  Compression involves a complementary pair of systems, a compressor (encoder) and\n",
    "a decompressor (decoder). The encoder converts the source data into a compressed form\n",
    "(occupying a reduced number of bits) prior to transmission or storage and the decoder converts\n",
    "the compressed form back into a representation of the original video data. The encoder/decoder\n",
    "pair is often described as a CODEC (enCOder/ DECoder)    \n",
    "\n",
    "  Data compression is achieved by removing redundancy, i.e. components that are not necessary for faithful reproduction of the data. Many types of data contain statistical redundancy\n",
    "and can be effectively compressed using lossless compression, so that the reconstructed data\n",
    "at the output of the decoder is a perfect copy of the original data. Unfortunately, lossless compression of image and video information gives only a moderate amount of compression. The\n",
    "best that can be achieved with current lossless image compression standards such as JPEG-LS\n",
    " is a compression ratio of around 3–4 times.  \n",
    " \n",
    " Lossy compression is necessary to achieve\n",
    "higher compression. In a lossy compression system, the decompressed data is not identical to\n",
    "the source data and much higher compression ratios can be achieved at the expense of a loss\n",
    "of visual quality. Lossy video compression systems are based on the principle of removing\n",
    "subjective redundancy, elements of the image or video sequence that can be removed without\n",
    "significantly affecting the viewer’s perception of visual quality.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook scope \n",
    "\n",
    "Most video coding methods exploit both temporal and spatial redundancy to achieve\n",
    "compression.   \n",
    "In this notebook , we will focus on how to exploit  spatial redundancy .  \n",
    "In the spatial domain, there is usually a high correlation between\n",
    "pixels (samples) that are close to each other, i.e. the values of neighbouring samples are often\n",
    "very similar.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimated Time to run notebook is  25 Minutes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Flow :\n",
    "code is divided into 6 main sections  \n",
    "\n",
    "* Import necessary libraries and huffman and dct project files  \n",
    "\n",
    "\n",
    "* Functions that handle the following \n",
    "                            * Counting video frames \n",
    "                            * Converting video to frames \n",
    "                            * Given a list of frames/images , write it to a specified directory \n",
    "                            * Converting frames to video\n",
    "                            * Creating thumbnails from images with the aid of PIL library\n",
    "                            \n",
    "* Color space conversion \n",
    "                            * Converting from rgb to YCrCb and vice versa \n",
    "                            * Creating images out of numpy arrays \n",
    "                            * Merging y, cr , cb component back into ycrcb image \n",
    " \n",
    "* Main function Video codec \n",
    "                            * loop over every video frame . Split it to its y, cr, cb componets \n",
    "                            * Apply low compression on y component while applying high compression on cr, cb using DCT \n",
    "                            * Apply entropy encoding \" Huffman\"\n",
    "                            \n",
    " \n",
    "* Quantative analysis       \n",
    "                            * Calculate time to encode/decode certain number of frames . \n",
    "                            * Compression ratio \n",
    "                            \n",
    "                            \n",
    "* References                \n",
    "                            * online Lectures\n",
    "                            * online course \n",
    "                            * Text book for python coding \n",
    "                            * Technical skills using python \n",
    "                            \n",
    "                            \n",
    "                            \n",
    "                            \n",
    "                            \n",
    "                            \n",
    "                            \n",
    "                            \n",
    "                            \n",
    "                            \n",
    "                                                    \n",
    "                            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import necessary libraries and huffman and dct project files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt \n",
    "#import imutlis # make sure to install it In anacoda prompt \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from encoder import reshape_image\n",
    "import main as m\n",
    "import natsort \n",
    "import timeit \n",
    "import glob\n",
    "plt.rcParams['figure.figsize']=(20,10) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions that handle the following\n",
    "\n",
    "                     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Counting video frames \n",
    "                      \n",
    "                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_frames_manual(video):\n",
    "    # initialize the total number of frames read\n",
    "    total = 0\n",
    " \n",
    " # loop over the frames of the video\n",
    "    while True:\n",
    "     # grab the current frame\n",
    "        (grabbed, frame) = video.read() \n",
    "        \n",
    "     # check to see if we have reached the end of the\n",
    "     # video\n",
    "        if not grabbed:\n",
    "            break\n",
    " \n",
    "     # increment the total number of frames read\n",
    "    \n",
    "        total += 1\n",
    " \n",
    "     # return the total number of frames in the video file\n",
    "    return total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting video to frames "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def videoToFrames(my_dir,no_frames): \n",
    "      \n",
    "    # Path to video file \n",
    "    my_vid = cv2.VideoCapture(my_dir) \n",
    "  \n",
    "    # Used as counter variable \n",
    "    count = 0\n",
    "  \n",
    "\n",
    "    frames = []\n",
    "    grey_frames=[]\n",
    "    for i in range(no_frames):\n",
    "      success, image = my_vid.read()\n",
    "      grey_image= cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "      frames.append(image)\n",
    "      grey_frames.append(grey_image)  \n",
    "    return frames,grey_frames;  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Given a list of frames/images , write it to a specified directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeImagesToFolder(folder,frameList):\n",
    "    \n",
    "    for i in range (len(frameList)):\n",
    "        cv2.imwrite(os.path.join(folder,\"frame{:2d}.jpg\".format(i)), frameList[i])     # save frame as JPEG file\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### convert_frames_to_video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_frames_to_video(image_folder,video_name):\n",
    "  \n",
    "\n",
    "  \n",
    "\n",
    "  images = [img for img in os.listdir(image_folder) if img.endswith(\".jpg\")]\n",
    "  frame = cv2.imread(os.path.join(image_folder, images[0]))\n",
    "  height, width, layers = frame.shape\n",
    "\n",
    "#video = cv2.VideoWriter(video_name, 0, 1, (width,height))\n",
    "  video = cv2.VideoWriter(video_name, 0, 29.97, (width,height))\n",
    "\n",
    "  for image in images:\n",
    "          video.write(cv2.imread(os.path.join(image_folder, image)))\n",
    "\n",
    "  cv2.destroyAllWindows()\n",
    "  video.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating thumbnails from images with the aid of PIL library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_image(dir,size_num,file_name):\n",
    "    for f in os.listdir(dir):                  \n",
    "            i=Image.open('images/{}'.format(f))\n",
    "            fn,fext=os.path.splitext(f)\n",
    "            i.thumbnail(size_num)\n",
    "            i.save(file_name+'/{}_480{}'.format(fn,fext))\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Color Space Conversion\n",
    "  Following block has these capabilites respectively \n",
    "                            * Converting from rgb to YCrCb and vice versa \n",
    "                            * Creating images out of numpy arrays \n",
    "                            * Merging y, cr , cb component back into ycrcb image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_from_rgb_to_yuv(rgb_img):\n",
    "    yuv_img = rgb_img.convert('YCbCr')\n",
    "    y, cb, cr = yuv_img.split()\n",
    "    return y,cb,cr \n",
    "\n",
    "def convert_from_yuv_to_rgb(yuv_img):\n",
    "    if yuv_img.mode != 'RGB':\n",
    "        rgb_img = yuv_img.convert('RGB')\n",
    "    return rgb_img\n",
    "\n",
    "# Use PIL to create an image from the new array of pixels\n",
    "\n",
    "\n",
    "def convert_list_to_y_cr_cb_component_img(component_list):\n",
    "    cb_d= np.array(component_list, dtype=np.uint8)\n",
    "    cb_d = Image.fromarray(cb_d)\n",
    "    return cb_d\n",
    "\n",
    "    \n",
    "    \n",
    "# this is how to convert components back to ycbcr , y ,cb,cr should be images instead of arrays  that is why we need \n",
    "#def convert_list_to_y_cr_cb_component_img(component_list):\n",
    "    \n",
    "    \n",
    "def merge_y_cb_cr_components(y,cb,cr):\n",
    "      merged_ycbcr=Image.merge('YCbCr', (y, cb, cr))\n",
    "      return merged_ycbcr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main  function \n",
    "- Steps are to convert video to frames , and then write these frames into folder , then check if nothing wrong has happened by   converting it to video composed of 60 frames .\n",
    "- We then resize video to be of quality 720_480 to make it take less time while encoding and decoding \n",
    "  if a frame has a size of 1920_1080 it will take 378 seconds in video codec \n",
    "  while it will take 6 seconds if it was of size 720*480\n",
    "- Get resized original video \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "A,g_frames=videoToFrames(\"zootopiasum_1.avi\",60)\n",
    "\n",
    "folder='images'\n",
    "writeImagesToFolder(folder,A)\n",
    "\n",
    "convert_frames_to_video('images','video.avi')\n",
    "\n",
    "resize_image('images',(720,480),'resized_frames_720_480')\n",
    "\n",
    "convert_frames_to_video('resized_frames_720_480','original_video_just_resized_bigger.avi')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * Loop over every video frame, split it to its y, cr, cb components. \n",
    " * Apply low compression on y component while applying high compression on cr, cb using DCT \n",
    " * Apply entropy encoding \" Huffman\"\n",
    " * Apply IDCT , huffman decoder \n",
    " * merge y, cr , cb components into y_cr_cb \n",
    " * convert it back to rgb images \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timeit.default_timer()\n",
    "\n",
    "y_encoded=[]\n",
    "cb_encoded=[]\n",
    "cr_encoded=[]\n",
    "\n",
    "cb_reconstructed=[]\n",
    "cr_reconstructed=[]\n",
    "y_reconstructed=[]\n",
    "\n",
    "y_d=[]\n",
    "cb_d=[]\n",
    "cr_d=[]\n",
    "\n",
    "d_rgb_img=[]\n",
    "\n",
    "y_len=0\n",
    "cb_len=0\n",
    "cr_len=0\n",
    "\n",
    "\n",
    "j=0\n",
    "\n",
    "for i in glob.glob('resized_frames_720_480/*.jpg'): #assuming jpg # how to read pil images from a file\n",
    "                   \n",
    "        rgb_img=Image.open(i)\n",
    "        yuv_img = rgb_img.convert('YCbCr')\n",
    "        y, cb, cr = yuv_img.split()\n",
    "       \n",
    "        \n",
    "        # encoder\n",
    "        huffcoded, code_dict, n_rows, n_columns = m.encode(y, 8, m.table_8_low)\n",
    "        y_len= y_len + len(huffcoded)    \n",
    "        y_encoded.append(huffcoded)  \n",
    "        #decoder\n",
    "        y_reconstructed.append(m.decode(y_encoded[j], code_dict,  n_rows, n_columns, 8, m.table_8_low))\n",
    "        y_arr=(np.array(y_reconstructed[j], dtype=np.uint8)) # con \n",
    "        y_d.append(Image.fromarray(y_arr))\n",
    "        \n",
    "        \n",
    "        # encoder\n",
    "        huffcoded, code_dict, n_rows, n_columns = m.encode(cb, 16, m.table_16_high)\n",
    "        cb_encoded.append(huffcoded)\n",
    "        cb_len= cb_len+ len(huffcoded)\n",
    "        \n",
    "        # decoder\n",
    "        cb_reconstructed.append(m.decode(cb_encoded[j], code_dict,  n_rows, n_columns, 16, m.table_16_high))\n",
    "        cb_arr= np.array(cb_reconstructed[j], dtype=np.uint8) # con \n",
    "        cb_d.append(Image.fromarray(cb_arr))\n",
    "        \n",
    "# Use PIL to create an image from the new array of pixels\n",
    "\n",
    "        #encoder\n",
    "    \n",
    "        huffcoded, code_dict, n_rows, n_columns = m.encode(cr, 16, m.table_16_high)\n",
    "        cr_encoded.append(huffcoded)\n",
    "        cr_len= cr_len + len(huffcoded)  \n",
    "        #decoder\n",
    "        cr_reconstructed.append(m.decode(cr_encoded[j], code_dict,  n_rows, n_columns, 16, m.table_16_high))\n",
    "        cr_arr= np.array(cr_reconstructed[j], dtype=np.uint8) # con \n",
    "        cr_d.append(Image.fromarray(cr_arr))\n",
    "        \n",
    "        d_y_cr_cb=merge_y_cb_cr_components(y_d[j],cb_d[j],cr_d[j])  # con \n",
    "        \n",
    "        if d_y_cr_cb.mode != 'RGB':\n",
    "            d_rgb_img.append(d_y_cr_cb.convert('RGB')) #con\n",
    "# Use PIL to create an image from the new array of pixels\n",
    "        j=j+1\n",
    "\n",
    "encoding_decoding_time=timeit.default_timer() - start  \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Image type conversion** : convert from PIL image to open_cv_image to be able to use writeImagesToFolder ,and convert_frames_to_video function .\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# convert from PIL image to open_cv_image \n",
    "open_cv_images=[]\n",
    "\n",
    "l=len( d_rgb_img)\n",
    "\n",
    "for i in range (l):  \n",
    "    pil_image =d_rgb_img[i].convert('RGB') \n",
    "    open_cv_image = np.array(pil_image) \n",
    "# Convert RGB to BGR \n",
    "    open_cv_image = open_cv_image[:, :, ::-1].copy() \n",
    "    open_cv_images.append(open_cv_image)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "writeImagesToFolder(\"decoded_frames\", open_cv_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_frames_to_video(\"decoded_frames\",\"decoded_video.avi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantative analysis       \n",
    "                            * Calculate time to encode/decode certain number of frames . \n",
    "                            * Compression ratio "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_compression_ratio(frames_num,no_bandits,width,height,no_bits_per_pixel,encoded_total_seq_len):\n",
    "    \n",
    "    compression_ratio=(frames_num*no_bandits*width*height*no_bits_per_pixel)/encoded_total_seq_len\n",
    "    \n",
    "    return compression_ratio "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23.507928583443526"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames_num=60\n",
    "no_bandits=3\n",
    "width=720\n",
    "height=480\n",
    "no_bits_per_pixel=8\n",
    "encoded_total_seq_len=y_len+cb_len+cr_len\n",
    "\n",
    "calculate_compression_ratio(frames_num,no_bandits,width,height,no_bits_per_pixel,encoded_total_seq_len)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.34007653693334"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding_decoding_time_in_minutes=encoding_decoding_time/60\n",
    "encoding_decoding_time_in_minutes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "  \n",
    "\n",
    "#### Online lectures ( Really useful)\n",
    "https://www.youtube.com/watch?v=OdYlNAFYq44&t=2033s  \n",
    "https://www.youtube.com/watch?v=Tm4C2ZFd3zE&t=1347s  \n",
    "https://www.youtube.com/watch?v=jRrs9OxLTYM\n",
    "\n",
    "#### Online course \n",
    "https://www.coursera.org/learn/digital/home/welcome  \n",
    "\n",
    "####  Textbook for python coding  \n",
    "Image Operators: Image Processing in Python  \n",
    "link to download http://93.174.95.29/_ads/9B2E3E52CDD3BA0195FD13256177470B\n",
    "\n",
    "#### Textbook for concept itself \n",
    "\n",
    " \"H.264 and MPEG-4 Video Compression Video Coding for Next-generation Multimedia\" *By Iain E. G. Richardson The Robert Gordon University, Aberdeen, UK\n",
    "\n",
    "\n",
    "#### Useful video about yuv color space \n",
    "https://www.youtube.com/watch?v=SjN_vCDi6_I  \n",
    "\n",
    "#### useful video about resizing images using pil library   \n",
    "https://www.youtube.com/watch?v=6Qs3wObeWwc\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Python skills \n",
    "\n",
    "https://stackoverflow.com/questions/33311153/python-extracting-and-saving-video-frames  \n",
    "\n",
    "https://www.pyimagesearch.com/2017/01/09/count-the-total-number-of-frames-in-a-video-with-opencv-and-python/  \n",
    "\n",
    "\n",
    "https://www.geeksforgeeks.org/python-pil-image-convert-method/  \n",
    "\n",
    "\n",
    "https://stackoverflow.com/questions/2797102/python-imaging-ycbcr-problems  \n",
    "\n",
    "\n",
    "\n",
    "https://stackoverflow.com/questions/5800009/python-and-pil-pixel-values-different-for-gif-and-jpeg  \n",
    "\n",
    "\n",
    "https://stackoverflow.com/questions/11064786/get-pixels-rgb-using-pil  \n",
    "\n",
    "\n",
    "http://2017.compciv.org/guide/topics/python-nonstandard-libraries/pillow.html\n",
    "\n",
    "https://www.geeksforgeeks.org/python-pil-getpixel-method/  \n",
    "\n",
    "https://stackoverflow.com/questions/46923244/how-to-create-image-from-a-list-of-pixel-values-in-python3    \n",
    "\n",
    "https://stackoverflow.com/questions/39939595/save-different-channels-of-ycbcr-as-seperate-images-python    \n",
    "\n",
    "https://stackoverflow.com/questions/26392336/importing-images-from-a-directory-python  \n",
    "\n",
    "https://stackoverflow.com/questions/14134892/convert-image-from-pil-to-opencv-format  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
