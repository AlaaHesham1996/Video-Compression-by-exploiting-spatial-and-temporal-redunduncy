{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Motion_Estimation_and_Compensation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pvg-WHKAu0qc",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt \n",
        "#import imutlis # make sure to install it In anacoda prompt \n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from encoder import reshape_image\n",
        "import main as m\n",
        "import math\n",
        "from PIL import Image\n",
        "import timeit \n",
        "import glob"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WWLDe0B8rj9A"
      },
      "source": [
        "**We used the optimized 2-D logaritmatic Fast Search Motion Estimation Algorithm**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TXyxbg7faoUt",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "> Theory\n",
        "\n",
        "\n",
        "**The 2-D search depends mainly on the theory saying that if you have a lower matching figure value at a point then the minmum would be close**\n",
        "**It monotically increases whever you drift away from the minimum at all the direction, up or down or left or right or diagonally**\n",
        "\n",
        "\n",
        "> Algorithm\n",
        "\n",
        "\n",
        "**-So The idea is basically, instead of searching the whole window blocks as in the regular sratch, we start by searching in the refrenece frame in 5 positions, which are the same the positon as in the to-be predicted frame, the one P/2 above it, the one P/2 below it, the one P/2 to the right of it, and the one P/2 to the left of it, Where P is the window size  ***\n",
        "\n",
        "\n",
        "**-After that, we find a position, we go there and do the same operaton again. But if the minimum among the five positons was found to be the orignal central point then it we will update the value of P by  2, and so on till we get P=1.**\n",
        "\n",
        "\n",
        "**-When P=1, we go to a regular search, where we compare the values comming from the whole nine blocks around the central one; the one above, below, right,left, and the four diagonal ones**\n",
        "\n",
        "                                                                                 \n",
        "> Impementation\n",
        "\n",
        "\n",
        "**It could be implemented using recursive function that has a base case that checks if P \"the window size\" is bigger than 1 and 2 recursive calls one for the case of finding another minimum, and another one if the minimum was the centre**\n",
        "\n",
        "**We used MAP to know the minimum difference**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8Xfc5WkeJ2M4",
        "colab": {}
      },
      "source": [
        "def logSearch(orgR,orgC,i,j,P,search_range,block_height, block_width, refFrame,currFrame):\n",
        " #The varibales \"orgR and orgC\" used to keep the original coordiante of our block untouched when recursion\n",
        "  #\n",
        "  this=-1   \n",
        "  if(search_range>1):#Stop condition, after which the recursion will stop \n",
        "    ind=-1\n",
        "    #Array used to compute the similarity between our block and the candidate blocks \n",
        "    siml=[0 for i in range(5)]\n",
        "    Min=9999999999999 #Mimum value to return the minimum of the siml array\n",
        "    m=i\n",
        "    n=j\n",
        "    r=(math.ceil(search_range/2))*block_height  \n",
        "    c=(math.ceil(search_range/2))*block_width\n",
        "    for V in range (j-c,j+c+1,c): \n",
        "      #Divided by two by definition, this returns -p/2, 0,p/2 \n",
        "     for H in range (i-r,i+r+1,r):\n",
        "        #To stop at the window edges \n",
        "      if H<=(orgR+P*block_height) and V <=(orgC+P*block_width) and H>=(orgR-P*block_height) and V >=(orgC-P*block_width):\n",
        "       if H>-1 and V>-1 and H<=(refFrame.shape[0]-block_height) and V<=(refFrame.shape[1]-block_height):#To stop it at the frame edges  \n",
        "        if ((V)==j or (H)==i): \n",
        "\n",
        "         #To get rid of the corner cases which we doesn't use in the 2D logarithmatic search, the second condition \n",
        "        #is to ensure that it didn't exculde the center which we need in our calculations \n",
        "          ind+=1\n",
        "          for k in range(block_height): #To loop in all the pixels in the block\n",
        "            for l in range(block_width):\n",
        "              siml[ind]+= abs(currFrame[orgR+k,orgC+l]-(refFrame[H+k,V+l]))\n",
        "          if(H==orgR and V==orgC):\n",
        "            this=siml[ind]\n",
        "          if siml[ind]<Min: #get the minimum index\n",
        "              Min=siml[ind]\n",
        "              m=H\n",
        "              n=V\n",
        "          if this==Min:\n",
        "              m=orgR\n",
        "              n=orgC\n",
        "    #print(siml)\n",
        "       #If the minimum was the center, then divide the range by two, O.W, leave it the same\n",
        "    if((m==i) and (n==j)):\n",
        "      return logSearch(orgR,orgC,m,n,P,search_range/2, block_height,block_width, refFrame,currFrame)\n",
        "     \n",
        "    else:\n",
        "      return logSearch(orgR,orgC,m,n,P,search_range, block_height,block_width, refFrame,currFrame)\n",
        "     \n",
        "    \n",
        "  else:   \n",
        "     #The final iteration, where we iterate on the current center and all neighbouring 8 blocks\n",
        "\n",
        "     ind=-1\n",
        "    #Array used to compute the similarity between our block and the candidate blocks \n",
        "     siml=[0 for i in range(9)]\n",
        "     Min=9999999999999\n",
        "     for q in range(-1,2,1): #gives -1 0 1 \n",
        "      for a in range(-1,2,1):   \n",
        "        H=q*block_height+i\n",
        "        V=a*block_width+j\n",
        "        if H<=(orgR+P*block_height) and V <=(orgC+P*block_width) and H>=(orgR-P*block_height) and V >=(orgC-P*block_width):\n",
        "         if H>-1 and V>-1 and H<=refFrame.shape[0]-block_height and V<=refFrame.shape[1]-block_width:\n",
        "          ind+=1\n",
        "          for k in range(block_height): #To loop in all the pixels in the block\n",
        "            for l in range(block_width):\n",
        "              siml[ind]+= abs(currFrame[orgR+k,orgC+l]-(refFrame[H+k,V+l]))\n",
        "          if (H==orgR and V==orgC):\n",
        "            this=siml[ind]\n",
        "          if siml[ind]<=Min: #get the minimum index               \n",
        "                Min=siml[ind]\n",
        "                m=H\n",
        "                n=V\n",
        "          if Min==this:\n",
        "             m=orgR\n",
        "             n=orgC\n",
        "     return m,n;\n",
        "               "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZ2hyQCqlES7",
        "colab_type": "text"
      },
      "source": [
        "**And here is the regular test algorithm**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ls01zuwsI4bk",
        "colab": {}
      },
      "source": [
        "def Search(orgR,orgC,P,block_size, refFrame,currFrame): #This is the simple search algorithm provided in the text, you can test it by uncomenting it in the main funciton\n",
        "      siml=[0 for i in range((2*P*block_size)**2)]\n",
        "      ind=-1\n",
        "      m=orgR\n",
        "      n=orgC\n",
        "      Min=9999999999999999\n",
        "      for i in range(orgR-(P*block_size),orgR+(P*block_size),block_size):\n",
        "        for j in range(orgC-(P*block_size),orgC+(P*block_size),block_size):\n",
        "         if i >-1 and j>-1 and i<=(currFrame.shape[0]-block_size) and j<=(currFrame.shape[1]-block_size):\n",
        "          ind+=1\n",
        "          for k in range(block_size): #To loop in all the pixels in the block\n",
        "            for l in range(block_size):\n",
        "              siml[ind]+= abs(currFrame[orgR+k,orgC+l]-(refFrame[i+k,j+l]))\n",
        "          if siml[ind]<=Min: #get the minimum index               \n",
        "                Min=siml[ind]\n",
        "                m=i\n",
        "                n=j\n",
        "        \n",
        "      return m,n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pb3YlJ88lQgI",
        "colab_type": "text"
      },
      "source": [
        "**Simple Subtraction**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5ZWhlbX21etO",
        "colab": {}
      },
      "source": [
        "#Subtraction\n",
        "def frame_subtract(fr1,fr2):\n",
        "     k=np.int32(fr1)-np.int32(fr2) #type casted as the default \"int8\" ignores the negative\n",
        "     \n",
        "     return k;"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R0PfVX4flWdy",
        "colab_type": "text"
      },
      "source": [
        "**Luma Component Motion estimation and compensation Encoder**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tRuYnSZnJnKo",
        "colab": {}
      },
      "source": [
        "def Encoder(ref,current,bs,P):\n",
        " motion_compensated =  [[0 for x in range(ref.shape[1])] for y in range(ref.shape[0])] \n",
        " Residuals=np.array(motion_compensated)\n",
        " MV=[]\n",
        " for i in range(0,ref.shape[0],bs):\n",
        "   for j in range(0,ref.shape[1],bs):\n",
        "    m,n=logSearch(i,j,i,j,P,P,bs,bs,ref,current)\n",
        "    #m,n=Search(i,j,P,bs,ref,current)\n",
        "     #Both codes are written, the code in the above line is a fast research algorithm\n",
        "    #uncomment the Search function and comment the logSearch function if you want to try the typical search method\n",
        "    MV.append([m,n]) #The motion vectors list to be transmitted with the residuals\n",
        "    for k in range(bs): #To loop in all the pixels in the block\n",
        "            for l in range(bs):\n",
        "               Residuals[i+k,j+l]=frame_subtract(ref[m+k,n+l],current[i+k,j+l])\n",
        "      \n",
        " Motion_Vectors=np.array(MV)\n",
        " return Residuals, Motion_Vectors     ;    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0S-zDH1Ild4I",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "**Chroma Component Encoder**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GqgYDk-lwphV",
        "colab": {}
      },
      "source": [
        "def EncodeChroma(ref,current,MV,bs):\n",
        " Residuals=  np.array([[0 for x in range(ref.shape[1])] for y in range(ref.shape[0])]) \n",
        "\n",
        " for pos in range(MV.shape[0]):#The way is used the index of the motion vector is explained in the following text cell\n",
        "  n_blocks=ref.shape[1]/bs\n",
        "  r=int(math.floor(pos/n_blocks)*bs)\n",
        "  c=int((pos%n_blocks)*bs)\n",
        "\n",
        "  for k in range(bs): #To loop in all the pixels in the block\n",
        "            for l in range(bs):\n",
        "               Residuals[r+k,c+l]=frame_subtract(ref[MV[pos,0]+k,MV[pos,1]+l],current[r+k,c+l])\n",
        " return Residuals"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GtlQiyJWxq0C"
      },
      "source": [
        "**Prediction, i.e Decoding**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "akkizFKK6ZhS",
        "colab": {}
      },
      "source": [
        "def Predict(ref,Motion_Vectors,Residuals,bs):\n",
        " Predicted=np.array([[0 for x in range(ref.shape[1])] for y in range(ref.shape[0])])\n",
        " for pos in range(Motion_Vectors.shape[0]):#The way is used the index of the motion vector is explained in the following text cell\n",
        "  n_blocks=ref.shape[1]/bs\n",
        "  r=int(math.floor(pos/n_blocks)*bs)\n",
        "  c=int((pos%n_blocks)*bs)\n",
        "  for k in range(bs): #To loop in all the pixels in the block\n",
        "      for l in range(bs):\n",
        "       Predicted[r+k,c+l]=frame_subtract(ref[Motion_Vectors[pos,0]+k,Motion_Vectors[pos,1]+l],Residuals[r+k,c+l])\n",
        " return(Predicted)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jsinCE42AUbb"
      },
      "source": [
        "**How to get the position of the current frame block position using the position(index) of the motion vector denoted PO?** \n",
        "\n",
        "**row=(floor((Po)/(width of the frame/block_width)))*Block Width**\n",
        "\n",
        "**clmn=remainder of the above equation*Block width**\n",
        "Given width=height"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9UqvcnkHZ-BD",
        "colab_type": "text"
      },
      "source": [
        "### Entropy encoding using Huffman"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSskqFFaZ-BG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from huffman import encode as h_encode\n",
        "from huffman import decode as h_decode\n",
        "\n",
        "def huffman_encode(rlcoded):\n",
        "    \n",
        "    # get a dictionary of the frequency of each symbol\n",
        "    counts_dict = dict(pd.Series(rlcoded).value_counts())\n",
        "    # get the huffman encoding dictionary / map\n",
        "    code_dict = h_encode(counts_dict)\n",
        "    # list of strings to one joined string\n",
        "    # encode each symbol to a string of zeros and ones and stitch together\n",
        "    huffcoded = ''.join([code_dict[i] for i in rlcoded])\n",
        "    return huffcoded, code_dict\n",
        "def huffman_decode(huffcoded, code_dict):\n",
        "    \"\"\"\n",
        "    Decodes a string of a List of 0 and 1\n",
        "     (same choice for decoder and encoder)\n",
        "    Args:\n",
        "        huffcoded : List or String of 0s and 1s code to be sent or stored\n",
        "        code_dict (dict): dict of symbol : code in binary\n",
        "    Returns:\n",
        "        rlcoded (numpy ndarray): 1d array\n",
        "    \"\"\"\n",
        "    return h_decode(huffcoded, code_dict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFhQXixZZ-BM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def calculate_compression_ratio(frames_num,no_bandits,width,height,no_bits_per_pixel,encoded_total_seq_len):\n",
        "    \n",
        "    compression_ratio=(frames_num*no_bandits*width*height*no_bits_per_pixel)/encoded_total_seq_len\n",
        "    \n",
        "    return compression_ratio \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BysF5qc2Z-BX",
        "colab_type": "text"
      },
      "source": [
        "### Low Compression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MjNG1rkOZ-BZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "#============================================Timer starts===============================================#\n",
        "start = timeit.default_timer()\n",
        "  \n",
        "# Read Video \n",
        "vid=cv2.VideoCapture('zootopiasum_1.avi')\n",
        "#vid=cv2.VideoCapture('gsm.avi')\n",
        "#Get the input video frame width\n",
        "fw=int(vid.get(3))\n",
        "#Get the input video frame height\n",
        "fh=int(vid.get(4))\n",
        "#Get the input video frame rate\n",
        "frps = vid.get(cv2.CAP_PROP_FPS)\n",
        "# Define the codec and create VideoWriter object To create the output video\n",
        "fourcc = cv2.VideoWriter_fourcc('M','J','P','G')\n",
        "out = cv2.VideoWriter('output.avi',fourcc,frps , (fw,fh),1)\n",
        "# Get the number of frames\n",
        "length = int(vid.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "# Get frame-by-frame\n",
        "frame=[]\n",
        "#Intializing the yucrcr comonents\n",
        "yp=np.array([[[0 for x in range(fw)] for y in range(fh)] for z in range(length)])\n",
        "cb=np.array([[[0 for x in range(fw)] for y in range(fh)] for z in range(length)])\n",
        "cr=np.array([[[0 for x in range(fw)] for y in range(fh)] for z in range(length)])\n",
        "c=15; #Just a counter used to know when to send an I frame\n",
        "bs=8 #Block Size\n",
        "P=8 #Search Range\n",
        "ha=0\n",
        "for i in range(15):\n",
        "    success, frame = vid.read();\n",
        "    # Our operations on the frame come here\n",
        "    if (success==1):\n",
        "     rbg = cv2.cvtColor((frame), cv2.COLOR_BGR2RGB);\n",
        "     pill=Image.fromarray(rbg)\n",
        "     yuv_img = pill.convert('YCbCr')\n",
        "     yp[i], cb[i], cr[i] = yuv_img.split()\n",
        "     ha+=1\n",
        "\n",
        "#The encoder and the decoder\n",
        "j=0\n",
        "#===========================================Compression ratio parameters====================================#\n",
        "R_len=0\n",
        "RCB_len=0\n",
        "RCR_len=0\n",
        "M_len=0\n",
        "ref_y_len=0\n",
        "ref_cb_len=0\n",
        "ref_cr_len=0\n",
        "\n",
        "for i in range(15):\n",
        "    if c==15 :#We are using I frame every 15 frames\n",
        "        j=i\n",
        "        c=0 \n",
        "        \n",
        "        ref_y=yp[j,:,:]\n",
        "        ref_cb=cb[j,:,:]\n",
        "        ref_cr=cr[j,:,:]\n",
        "        #=======================================DCT and huffman Integration=================================#\n",
        "        ref_y_img=Image.fromarray(ref_y)\n",
        "        ref_cb_img=Image.fromarray(ref_cb) \n",
        "        ref_cr_img=Image.fromarray(ref_cr)\n",
        "    \n",
        "        ref_y_encoded, code_dict, n_rows, n_columns = m.encode(ref_y_img, 8, m.table_8_low)\n",
        "        reconstructed_y=m.decode(ref_y_encoded, code_dict,  n_rows, n_columns, 8, m.table_8_low)\n",
        "        ref_y_len=ref_y_len+len(ref_y_encoded)       \n",
        "        \n",
        "    \n",
        "        ref_cb_encoded, code_dict, n_rows, n_columns = m.encode(ref_cb_img, 8, m.table_8_low)\n",
        "        reconstructed_cb=m.decode(ref_cb_encoded, code_dict,  n_rows, n_columns, 8, m.table_8_low)\n",
        "        ref_cb_len=ref_cb_len+len(ref_cb_encoded)\n",
        "        \n",
        "    \n",
        "        ref_cr_encoded, code_dict, n_rows, n_columns = m.encode(ref_cr_img, 8, m.table_8_low)\n",
        "        reconstructed_cr=m.decode(ref_cr_encoded, code_dict,  n_rows, n_columns, 8, m.table_8_low)\n",
        "        ref_cr_len=ref_cr_len+len(ref_cr_encoded)\n",
        "        #========================================Residual calculation ===================================#\n",
        "\n",
        "    R,M=Encoder(yp[j,:,:],yp[i,:,:],bs,P)    \n",
        "    RCB=EncodeChroma(cb[j,:,:],cb[i,:,:],M,bs)\n",
        "    RCR=EncodeChroma(cr[j,:,:],cr[i,:,:],M,bs)\n",
        "        #======================================Motion vector huffman======================================#\n",
        "        \n",
        "    wid,h_8=M.shape \n",
        "    M_h=M.reshape(-1)    \n",
        "    huffcoded, code_dict=huffman_encode(M_h)\n",
        "    M_len=M_len+len(huffcoded)\n",
        "    r_M_h=huffman_decode(huffcoded, code_dict)\n",
        "    r_M_h=np.asarray(r_M_h)\n",
        "    r_M_h=r_M_h.reshape(wid,h_8)    \n",
        "        #========================================DCT and huffman Integration cont'd=======================#\n",
        "\n",
        "    R_img= Image.fromarray(R)\n",
        "    RCB_img=Image.fromarray(RCB)\n",
        "    RCR_img=Image.fromarray(RCR)\n",
        "    \n",
        "    R_encoded, code_dict, n_rows, n_columns = m.encode(R_img, 8, m.table_8_low)\n",
        "    R_reconstructed=m.decode(R_encoded, code_dict,  n_rows, n_columns, 8, m.table_8_low)\n",
        "    R_len=R_len+ len(R_encoded)\n",
        "  \n",
        "    RCB_encoded,code_dict, n_rows, n_columns = m.encode(RCB_img, 8, m.table_8_low)\n",
        "    RCB_reconstructed=m.decode(RCB_encoded, code_dict,  n_rows, n_columns, 8, m.table_8_low)\n",
        "    RCB_len=RCB_len +len(RCB_encoded) \n",
        "\n",
        "    RCR_encoded,code_dict, n_rows, n_columns = m.encode(RCR_img, 8, m.table_8_low)\n",
        "    RCR_reconstructed=m.decode(RCR_encoded, code_dict,  n_rows, n_columns, 8, m.table_8_low)\n",
        "    RCR_len=RCR_len +len(RCR_encoded)   \n",
        "    \n",
        "  #The encoder done here\n",
        "    #==================================================prediction============================================================#\n",
        "    pry=Image.fromarray(np.uint8(Predict(reconstructed_y,r_M_h,R_reconstructed,bs)))\n",
        "    prcb=Image.fromarray(np.uint8(Predict(reconstructed_cb,r_M_h,RCB_reconstructed,bs))) \n",
        "    prcr=Image.fromarray(np.uint8(Predict(reconstructed_cr,r_M_h,RCR_reconstructed,bs))) \n",
        "\n",
        "    ycbcr2 = Image.merge('YCbCr', (pry, prcb, prcr))\n",
        "\n",
        "    if ycbcr2.mode != 'RGB':\n",
        "        final= np.array(ycbcr2.convert('RGB'))\n",
        "# Convert RGB to BGR \n",
        "    Final_wallahi = final[:, :, ::-1].copy() \n",
        "  #Final_wallahi = cv2.cvtColor(np.array(final), cv2.COLOR_RGB2BGR)\n",
        "\n",
        "    out.write(Final_wallahi)\n",
        "    c+=1\n",
        "# Release everything if job is finished\n",
        "vid.release()\n",
        "out.release()\n",
        "cv2.destroyAllWindows()\n",
        "#==========================================================Timer stops=============================================#\n",
        "\n",
        "temporal_model_spatial_model_time=timeit.default_timer() - start "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EA_7uRk4Z-Be",
        "colab_type": "code",
        "outputId": "bbffb033-9a4c-4a3b-a852-ccc7024d80f4",
        "colab": {}
      },
      "source": [
        "temporal_model_spatial_model_time/60  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10.192555068683335"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYG5WP7KZ-Bm",
        "colab_type": "code",
        "outputId": "89d5c245-de8b-419d-d181-0648b21b8f64",
        "colab": {}
      },
      "source": [
        "frames_num=15\n",
        "no_bandits=3\n",
        "width=720\n",
        "height=480\n",
        "no_bits_per_pixel=8\n",
        "encoded_total_seq_len=R_len+RCB_len+RCR_len+M_len+ref_y_len+ref_cb_len+ref_cr_len\n",
        "\n",
        "calculate_compression_ratio(frames_num,no_bandits,width,height,no_bits_per_pixel,encoded_total_seq_len)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20.263650919784666"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DcFqs9jjZ-B0",
        "colab_type": "text"
      },
      "source": [
        "### High Compression "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dV6NkOtQZ-B3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "start = timeit.default_timer()\n",
        "#===========================================Compression ratio parameters====================================#\n",
        "R_len=0\n",
        "RCB_len=0\n",
        "RCR_len=0\n",
        "M_len=0\n",
        "ref_y_len=0\n",
        "ref_cb_len=0\n",
        "ref_cr_len=0\n",
        "\n",
        "  \n",
        "# Read Video \n",
        "vid=cv2.VideoCapture('zootopiasum_1.avi')\n",
        "#vid=cv2.VideoCapture('gsm.avi')\n",
        "#Get the input video frame width\n",
        "fw=int(vid.get(3))\n",
        "#Get the input video frame height\n",
        "fh=int(vid.get(4))\n",
        "#Get the input video frame rate\n",
        "frps = vid.get(cv2.CAP_PROP_FPS)\n",
        "# Define the codec and create VideoWriter object To create the output video\n",
        "fourcc = cv2.VideoWriter_fourcc('M','J','P','G')\n",
        "out = cv2.VideoWriter('output.avi',fourcc,frps , (fw,fh),1)\n",
        "# Get the number of frames\n",
        "length = int(vid.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "# Get frame-by-frame\n",
        "frame=[]\n",
        "#Intializing the yucrcr comonents\n",
        "yp=np.array([[[0 for x in range(fw)] for y in range(fh)] for z in range(length)])\n",
        "cb=np.array([[[0 for x in range(fw)] for y in range(fh)] for z in range(length)])\n",
        "cr=np.array([[[0 for x in range(fw)] for y in range(fh)] for z in range(length)])\n",
        "c=15; #Just a counter used to know when to send an I frame\n",
        "bs=8 #Block Size\n",
        "P=8 #Search Range\n",
        "ha=0\n",
        "for i in range(15):\n",
        "    success, frame = vid.read();\n",
        "    # Our operations on the frame come here\n",
        "    if (success==1):\n",
        "     rbg = cv2.cvtColor((frame), cv2.COLOR_BGR2RGB);\n",
        "     pill=Image.fromarray(rbg)\n",
        "     yuv_img = pill.convert('YCbCr')\n",
        "     yp[i], cb[i], cr[i] = yuv_img.split()\n",
        "     ha+=1\n",
        "\n",
        "#The encoder and the decoder\n",
        "j=0\n",
        "\n",
        "R_len=0\n",
        "RCB_len=0\n",
        "RCR_len=0\n",
        "\n",
        "ref_y_len=0\n",
        "ref_cb_len=0\n",
        "ref_cr_len=0\n",
        "\n",
        "for i in range(15):\n",
        "    if c==15 :#We are using I frame every 15 frames\n",
        "        j=i\n",
        "        c=0 \n",
        "        ref_y=yp[j,:,:]\n",
        "        ref_cb=cb[j,:,:]\n",
        "        ref_cr=cr[j,:,:]\n",
        "#=======================================DCT and huffman Integration=================================#\n",
        "\n",
        "        ref_y_img=Image.fromarray(ref_y)\n",
        "        ref_cb_img=Image.fromarray(ref_cb) \n",
        "        ref_cr_img=Image.fromarray(ref_cr)\n",
        "    \n",
        "        ref_y_encoded, code_dict, n_rows, n_columns = m.encode(ref_y_img, 8, m.table_8_low)\n",
        "        reconstructed_y=m.decode(ref_y_encoded, code_dict,  n_rows, n_columns, 8, m.table_8_low)\n",
        "        ref_y_len=ref_y_len+len(ref_y_encoded)\n",
        "        \n",
        "        \n",
        "    \n",
        "        ref_cb_encoded, code_dict, n_rows, n_columns = m.encode(ref_cb_img, 16, m.table_16_high)\n",
        "        reconstructed_cb=m.decode(ref_cb_encoded, code_dict,  n_rows, n_columns, 16, m.table_16_high)\n",
        "        ref_cb_len=ref_cb_len+len(ref_cb_encoded)\n",
        "    \n",
        "        ref_cr_encoded, code_dict, n_rows, n_columns = m.encode(ref_cr_img, 16, m.table_16_high)\n",
        "        reconstructed_cr=m.decode(ref_cr_encoded, code_dict,  n_rows, n_columns, 16, m.table_16_high)\n",
        "        ref_cr_len=ref_cr_len+len(ref_cr_encoded)\n",
        "#=======================================     Residuals=================================#    \n",
        "\n",
        "    R,M=Encoder(yp[j,:,:],yp[i,:,:],bs,P)\n",
        "    RCB=EncodeChroma(cb[j,:,:],cb[i,:,:],M,bs)\n",
        "    RCR=EncodeChroma(cr[j,:,:],cr[i,:,:],M,bs)\n",
        "    \n",
        "      #======================================Motion vector huffman======================================#\n",
        "        \n",
        "    wid,h_8=M.shape \n",
        "    M_h=M.reshape(-1)    \n",
        "    huffcoded, code_dict=huffman_encode(M_h)\n",
        "    M_len=M_len+len(huffcoded)\n",
        "    r_M_h=huffman_decode(huffcoded, code_dict)\n",
        "    r_M_h=np.asarray(r_M_h)\n",
        "    r_M_h=r_M_h.reshape(wid,h_8)   \n",
        "    #=======================================DCT and huffman Integration cont'd=================================#\n",
        "\n",
        "    R_img= Image.fromarray(R)\n",
        "    RCB_img=Image.fromarray(RCB)\n",
        "    RCR_img=Image.fromarray(RCR)\n",
        "    \n",
        "    R_encoded, code_dict, n_rows, n_columns = m.encode(R_img, 8, m.table_8_low)\n",
        "    R_reconstructed=m.decode(R_encoded, code_dict,  n_rows, n_columns, 8, m.table_8_low)\n",
        "    R_len=R_len+ len(R_encoded)\n",
        "  \n",
        "    RCB_encoded,code_dict, n_rows, n_columns = m.encode(RCB_img, 16, m.table_16_high)\n",
        "    RCB_reconstructed=m.decode(RCB_encoded, code_dict,  n_rows, n_columns, 16, m.table_16_high)\n",
        "    RCB_len=RCB_len +len(RCB_encoded) \n",
        "\n",
        "    RCR_encoded,code_dict, n_rows, n_columns = m.encode(RCR_img, 16, m.table_16_high)\n",
        "    RCR_reconstructed=m.decode(RCR_encoded, code_dict,  n_rows, n_columns, 16, m.table_16_high)\n",
        "    RCR_len=RCR_len +len(RCR_encoded)   \n",
        "    \n",
        "  #The encoder done here\n",
        "    #=======================================Prediction =================================#\n",
        "\n",
        "    pry=Image.fromarray(np.uint8(Predict(reconstructed_y,r_M_h,R_reconstructed,bs)))\n",
        "    prcb=Image.fromarray(np.uint8(Predict(reconstructed_cb,r_M_h,RCB_reconstructed,bs))) \n",
        "    prcr=Image.fromarray(np.uint8(Predict(reconstructed_cr,r_M_h,RCR_reconstructed,bs))) \n",
        "\n",
        "    ycbcr2 = Image.merge('YCbCr', (pry, prcb, prcr))\n",
        "\n",
        "    if ycbcr2.mode != 'RGB':\n",
        "        final= np.array(ycbcr2.convert('RGB'))\n",
        "# Convert RGB to BGR \n",
        "    Final_wallahi = final[:, :, ::-1].copy() \n",
        "  #Final_wallahi = cv2.cvtColor(np.array(final), cv2.COLOR_RGB2BGR)\n",
        "\n",
        "    out.write(Final_wallahi)\n",
        "    c+=1\n",
        "# Release everything if job is finished\n",
        "vid.release()\n",
        "out.release()\n",
        "cv2.destroyAllWindows()\n",
        "temporal_model_spatial_model_time=timeit.default_timer() - start "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ytqn0UmDZ-B_",
        "colab_type": "code",
        "outputId": "1a31780b-68a7-44e0-d939-5db9222be462",
        "colab": {}
      },
      "source": [
        "temporal_model_spatial_model_time/60"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10.187802752783318"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1qEoNnzZ-CK",
        "colab_type": "code",
        "outputId": "4d743300-406f-414a-c351-510e1cd65219",
        "colab": {}
      },
      "source": [
        "encoded_total_seq_len=R_len+RCB_len+RCR_len+M_len+ref_y_len+ref_cb_len+ref_cr_len\n",
        "\n",
        "calculate_compression_ratio(frames_num,no_bandits,width,height,no_bits_per_pixel,encoded_total_seq_len)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25.078632769445736"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YXT2CS-fZ-CV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56RqOzCJZ-Cg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}